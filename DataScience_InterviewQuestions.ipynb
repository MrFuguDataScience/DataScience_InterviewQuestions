{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `10 Real Data Science Interview Questions`:\n",
    "\n",
    "**And SOLVE them; YAY!**\n",
    "\n",
    "`-----------------------`\n",
    "\n",
    "<font color=red>Mr Fugu Data Science</font>\n",
    "\n",
    "# (◕‿◕✿)\n",
    "\n",
    "\n",
    "`-----------------------------------`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **`Q 1`.)** You roll 2 different (*fair*) 6 sided dice. What is the expected value of their sum?\n",
    "\n",
    "**`Choose Answer`**:\n",
    "\n",
    "+ 7/2\n",
    "+ 6\n",
    "+ 7\n",
    "+ 12\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ `Lets work it out`:\n",
    "\n",
    "Remember: that a **random variable** is *an event* where we have a \"rule/function\" that \n",
    "assigns a value to our outcome. \n",
    "\n",
    "\n",
    "\n",
    "The Expected value will be: **E [ X ]= $\\sum(x)$ * P(X)**\n",
    "\n",
    "\n",
    "**<center>This Table is for Sum of 2 Dice</center>**\n",
    "\n",
    "\n",
    "| x  \t| P(X=x)  \t|\n",
    "|----\t|---------\t|\n",
    "| 2  \t| 1/36    \t|\n",
    "| 3  \t| 2/36    \t|\n",
    "| 4  \t| 3/36    \t|\n",
    "| 5  \t| 4/36    \t|\n",
    "| 6  \t| 5/36    \t|\n",
    "| 7  \t| 6/36    \t|\n",
    "| 8  \t| 5/36    \t|\n",
    "| 9  \t| 4/36    \t|\n",
    "| 10 \t| 3/36    \t|\n",
    "| 11 \t| 2/36    \t|\n",
    "| 12 \t| 1/36    \t|\n",
    "\n",
    "\n",
    "\n",
    "Therefore we have to do: \n",
    "\n",
    "**E [ X ]** = 2($\\frac{1}{36}$) + 3($\\frac{2}{36}$) + 3($\\frac{3}{36}$)+...11($\\frac{2}{36}$) + 12($\\frac{1}{36}$) = **7**\n",
    "\n",
    "**Answer: 7**\n",
    "\n",
    "`-------------------`\n",
    "\n",
    "`how could we do this fast: like under a minute?`\n",
    "\n",
    "+ Since this is a `fair` di, then you will have equal chance of any give face:\n",
    "then we can say ($\\frac{1}{6}$(1+2+3+4+5+6)) = 21/6 = 3.5 \n",
    "\n",
    "    + but we have 2 dice, so **n* 3.5 = 2*3.5 = 7**\n",
    "\n",
    "`----------------------`\n",
    "\n",
    "+ https://www.math.upenn.edu/~deturck/m170/wk8/lecture/prob4.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **`Q 2`.)** \n",
    "\n",
    "`def find_max(nums):\n",
    "    max_nums= floats(\"-inf\")\n",
    "    for num in nums:\n",
    "        if num > max_nums:\n",
    "            (*`<--insert code here --->`*)\n",
    "    return max_nums`\n",
    "    \n",
    "**`Choose Answer:`**\n",
    "\n",
    "+ num = max_nums\n",
    "\n",
    "+ max_nums += 1\n",
    "\n",
    "+ max_nums = num\n",
    "\n",
    "+ max_nums += num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-inf"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Work it out:\n",
    "\n",
    "import math\n",
    "max_nums= -math.inf\n",
    "def find_max(nums):\n",
    "    max_nums= -math.inf\n",
    "    for num in nums:\n",
    "        if num > max_nums: \n",
    "            max_nums = num\n",
    "    return max_nums\n",
    "\n",
    "\n",
    "find_max([1,2,8,4])\n",
    "\n",
    "# `_________________________________`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **`Q 3`. )** Which of the following algorithms is most suitable for binary classification?\n",
    "\n",
    "**`Choose Answer:`**\n",
    "\n",
    "+ K-Means\n",
    "\n",
    "+ Linear Regression\n",
    "\n",
    "+ Logistic Regression\n",
    "\n",
    "+ Simplex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work it out:\n",
    "\n",
    "*`Background to solve problem`*:\n",
    "\n",
    "**`Binary Classification`**: your assigning something to one of two categories. This can be great for `Categorical data`, think of a situation where it is (Yes/No), (Buy/Sell), etc.\n",
    "\n",
    "+ A common task involves using a Binary Classification in terms of a `Bernoulli Probability Distribution`. The Bernoulli Distribution takes into account (0,1) as your binary outcome for an event. \n",
    "    + Therefore, if you are using Classification, then your model will predict a probability belonging to either one class or the other. \n",
    "    \n",
    "`Common Related Algorithms`:\n",
    "\n",
    "+ Logistic Regression (*`Only Supports 2 classes`*)\n",
    "\n",
    "+ k-Nearest Neighbor\n",
    "\n",
    "+ Support Vector Machine (SVM)  (*`Only Supports 2 classes`*)\n",
    "\n",
    "+ Naive Bayes\n",
    "\n",
    "+ Decision Trees\n",
    "\n",
    "`-------------`\n",
    "\n",
    "+ **`K-Means`**: \n",
    "\n",
    "https://www.ibm.com/support/pages/clustering-binary-data-k-means-should-be-avoided\n",
    "\n",
    "\n",
    "+ **`Linear Regression`**: \n",
    "\n",
    "+ The predicted values is `Continous ` not probabilistic\n",
    "    + problems when data are imballanced\n",
    "    \n",
    "https://jinglescode.github.io/2019/05/07/why-linear-regression-is-not-suitable-for-classification/\n",
    "\n",
    "https://thestatsgeek.com/2015/01/17/why-shouldnt-i-use-linear-regression-if-my-outcome-is-binary/\n",
    "\n",
    "+ **`Simplex Algorithm or Coding (Not sure what they meant?)`**:\n",
    "\n",
    "Simplex Algorithm, is used in Linear Programming focusing on (optimization), using some form of constraint. \n",
    "\n",
    "`--------------------------------`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **`Q 4.)`** What is a requirement for primary keys in SQL?\n",
    "\n",
    "**`Choose Answer:`**\n",
    "\n",
    "+ Only a single column can be used as a primary key\n",
    "\n",
    "+ Primary keys must auto-increment\n",
    "\n",
    "+ Foreign keys only reference primary keys\n",
    "\n",
    "+ Primary keys must be unique and not null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work Through: \n",
    "\n",
    "+ you need Unique values\n",
    "    + Not Null\n",
    "    \n",
    "+ *Side note*: your primary key can spread across multiple columns as long as it does not have repeating values. \n",
    "\n",
    "+ It can auto-increment if you are creating a primary key and don't have columns that are useful or meaningful. \n",
    "\n",
    "+ THe foreign key will reference a primary key, but it is not contigent upon setting up a primary key."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **`Q 5.) `** Which approach should be used to reduce high bias in a neural net classifier?\n",
    "\n",
    "**`Choose Answer:`**\n",
    "\n",
    "+ Switch from logistic nodes to linear\n",
    "\n",
    "+ Switch from a neural net classifier to linear regression\n",
    "\n",
    "+ Increase the number of hidden layers\n",
    "\n",
    "+ Increase amount of training data\n",
    "\n",
    "`---------------------`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work it Out: \n",
    "\n",
    "*`Background`*\n",
    "\n",
    "When we talk about bias: we can think of the (Bias vs Variance) tradeoff. This will in turn lead to `Over or Under fitting`. \n",
    "\n",
    "+ High bias, means that we are not doing a good enough good for training our model beacause our error is high. \n",
    "\n",
    "+ If we had `high variance`: then our model would not accurately predict for the validation set. \n",
    "\n",
    "Therefore: if we Overfit, we may only be learning the current task but not generalizing our model which is the goal. Making something highly specific to solve only that problem with the current data is not a good approach and only will work with predicting your training set. \n",
    "\n",
    "Now: \n",
    "\n",
    "**Overfitting**\n",
    "\n",
    "`Low Bias`: Accurate for the training data\n",
    "\n",
    "`High Variance`: poor ability to predict on validation set\n",
    "\n",
    "\n",
    "**Underfitting**:\n",
    "\n",
    "`High Bias`: poorly trains on the training data\n",
    "\n",
    "`Low Variance`: poor ability to predict validation set\n",
    "\n",
    "\n",
    "# But how do we solve this (`Lowering Bias`)?\n",
    "\n",
    "+ We can Increase the Number of Epochs (*number of iterations*)\n",
    "    + Also, try a bigger network\n",
    "\n",
    "\n",
    "`--------------------`\n",
    "+ If we were dealing with the converse of this question: Variance\n",
    "\n",
    "    + then we would solve this differently, to lower the variance\n",
    "        + Increase training data\n",
    "        + Try regularization terms\n",
    "        + change the neural network archetecture \n",
    "\n",
    "\n",
    "`Linear`: will allow you to use a regularization term, but in turn increase bias while decreasing your variance.\n",
    "\n",
    "`Logistic`: \n",
    "\n",
    "https://missinglink.ai/guides/neural-network-concepts/neural-network-bias-bias-neuron-overfitting-underfitting/\n",
    "\n",
    "https://buzzrobot.com/bias-and-variance-11d8e1fee627\n",
    "\n",
    "https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **`Q 6.)`** Which SQL window function to compute time deltas between adjacent rows were created?\n",
    "\n",
    "**`Choose Answer:`**\n",
    "\n",
    "+ Select created - lag(created) over (partition by created) form table\n",
    "\n",
    "+ Select created - (selected min(created) from table) from table order by created\n",
    "\n",
    "+ Select created - first_value(crated) over (order by created) from table\n",
    "\n",
    "+ Select created - lag(created) over (order by created) from table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work it Out:\n",
    "\n",
    "+ First we will need to `lag()` function: which allows you to access rows adjacent (behind what we are viewing)\n",
    "    + Then do we use partition or over?\n",
    "        Partition: \n",
    "        Over: \n",
    "+ `first_value`: this is related to `lag()` but used instead if we want first value from a set of values\n",
    "\n",
    "`----------------------------`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **`Q 7.)`** If a classifier performs well on training: but, poor in production. What is most likely the problem?\n",
    "\n",
    "**`Choose Answer:`**\n",
    "\n",
    "+ High variance\n",
    "\n",
    "+ High bias\n",
    "\n",
    "+ High entropy\n",
    "\n",
    "+ High measurment noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work it Out:\n",
    "\n",
    "+ High Variance: poorly trains on validation \n",
    "\n",
    "+ `High Entropy`: I am assuming Cross-Entropy, if so it is a measure of the probability distribution between 2 events for a random variable. \n",
    "    + If used in the event of classifcation as a loss function\n",
    "    + you can think of how close you are to the actual distribution \n",
    "\n",
    "+ Noisy Data: can have effect, but can be minimized \n",
    "\n",
    "+ High Bias: poorly trains on training\n",
    "\n",
    "https://machinelearningmastery.com/cross-entropy-for-machine-learning/\n",
    "\n",
    "https://towardsdatascience.com/understanding-binary-cross-entropy-log-loss-a-visual-explanation-a3ac6025181a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **`Q 8.)`** When using SVM on a training set of 2 classes, what is the minimum possible number of support vectors?\n",
    "\n",
    "**`Choose Answer:`**\n",
    "\n",
    "+ 0\n",
    "\n",
    "+ 1\n",
    "\n",
    "+ 2\n",
    "\n",
    "+ Unlimited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work it out:\n",
    "\n",
    "`Answer`: 2, \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "https://www.researchgate.net/post/Support_Vector_Machines_How_to_find_the_minimum_number_of_support_vectors_for_a_machine_learning_classification_problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **`Q 9.)`** Which best describe cross validation?\n",
    "\n",
    "**`Answers:`**\n",
    "\n",
    "+ Eliminate training error\n",
    "\n",
    "+ Ensure convergence\n",
    "\n",
    "+ Prevent over fitting\n",
    "\n",
    "+ Handle very large training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work it Out:\n",
    "\n",
    "`Corss-validation`: is used when you have enough data to separate into train/test split for instance. Allowing you to run your experiement/test and compare your results with the left over data. (*also, aid in avoiding overfitting*), the purpose is to generalize your model after all.\n",
    "\n",
    "+ You have k-fold, leave out one method as other examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **`Q 10.)`** You train a model using gradient descent does not reach the cost functions global minimum. What's a possible reason why?\n",
    "\n",
    "**`Choose Answer:`**\n",
    "\n",
    "+ Add a regularization term to cost function \n",
    "\n",
    "+ Switch to a model with more parameters\n",
    "\n",
    "+ Reduce learning rate during gradient descent\n",
    "\n",
    "+ Use smaller training set\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work it out:\n",
    "\n",
    "+ Here is an interesting case: you may have reached a local minima or have a non convex function. \n",
    "\n",
    "Lets investigate our options:\n",
    " \n",
    "+ Using a `learning rate`: (too large) will create a circumstance where we get stuck in a local minima and will not converge.\n",
    " \n",
    "+ Convergence, also depends on the initialized parameters.\n",
    " \n",
    "# What do we want to achieve?\n",
    " \n",
    "+ Shrink the weights or coefficients\n",
    "+ remove higher degree polynomials (decrease model complexity and resolve overfitting)\n",
    " \n",
    "\n",
    "+ `Regularization`: this hyper-parameter, is used to adjust the bias term. \n",
    "\n",
    "+ Adding `paramters` to our model: such as weights can make you overshoot you minima and need to be considered. \n",
    " \n",
    "\n",
    "https://adityashrm21.github.io/All-About-Gradient-Descent/\n",
    " \n",
    "https://www.freecodecamp.org/news/how-to-pick-the-best-learning-rate-for-your-machine-learning-project-9c28865039a8/\n",
    " \n",
    "https://towardsdatascience.com/regularization-in-machine-learning-connecting-the-dots-c6e030bfaddd\n",
    "\n",
    "https://towardsdatascience.com/hyper-parameter-tuning-techniques-in-deep-learning-4dad592c63c8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Bonus`: Which guarantees that *P(A ${\\cap}$ B) = P(A) P(B)*\n",
    "\n",
    "+ A & B are correlated\n",
    "\n",
    "+ A & B are same event\n",
    "\n",
    "+ A & B are mutually exclusive\n",
    "\n",
    "+ A & B are independent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work it Out:\n",
    "\n",
    "+ \n",
    "\n",
    "+ Mutually exclusive: that is an (OR) problem not (AND) like we have here\n",
    "\n",
    "ex.) P(A∪B) = P(A) + P(B)\n",
    "\n",
    "+ `Answer`: Independent (their joint prob. is their interesection for example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`---------------------------`\n",
    "\n",
    "# LIKE , SHARE & \n",
    "\n",
    "# <font color=red> SUBscribe</font>\n",
    "\n",
    "`---------------------------`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Citations & Help & Good Knowledge:\n",
    "\n",
    "# ◔̯◔\n",
    "\n",
    "https://www.springboard.com/blog/machine-learning-interview-questions/\n",
    "\n",
    "https://neptune.ai/blog/f1-score-accuracy-roc-auc-pr-auc\n",
    "\n",
    "https://towardsdatascience.com/analytics-building-blocks-binary-classification-d205890314fc\n",
    "\n",
    "https://www.sciencedirect.com/topics/computer-science/binary-classification\n",
    "\n",
    "https://docs.aws.amazon.com/machine-learning/latest/dg/machinelearning-dg.pdf#binary-classification\n",
    "\n",
    "https://machinelearningmastery.com/types-of-classification-in-machine-learning/\n",
    "\n",
    "https://buzzrobot.com/bias-and-variance-11d8e1fee627\n",
    "\n",
    "https://towardsdatascience.com/a-gentle-journey-from-linear-regression-to-neural-networks-68881590760e\n",
    "\n",
    "https://www.sciencedirect.com/science/article/pii/S0370157319300766\n",
    "\n",
    "https://d4datascience.wordpress.com/2016/09/29/fbf/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
