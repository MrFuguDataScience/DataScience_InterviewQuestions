{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 Data Science Interview Questions `No.03`\n",
    "\n",
    "# <font color=red>Mr Fugu Data Science</font>\n",
    "\n",
    "# (‚óï‚Äø‚óï‚úø)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ex. 1 )** A disease that occurs in 1% of the population has a test with a 3% false positive rate and a 4% false negative rate. If the test comes back positive for a random member of the population, what's the chance they have the disease?\n",
    "\n",
    "`Answers`:\n",
    "\n",
    "+ 94%\n",
    "+ 97%\n",
    "+ 24%\n",
    "+ 9%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Work It Out`**:\n",
    "\n",
    "This is a classic `Bayes` problem: \n",
    "\n",
    "$P(A|B)= \\frac{P(B|A)P(A)}{P(B)}$\n",
    "\n",
    "*where the denominator is*: ${P(B)} = P(B|A) P(A)+P(B| \\bar A) P( \\bar A)$\n",
    "\n",
    "*and* $\\bar A =  not A$\n",
    "\n",
    "\n",
    "\n",
    "`----------------`\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "https://brownmath.com/stat/falsepos.htm\n",
    "\n",
    "https://www.youtube.com/watch?v=vZd5ZqWwTZI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can think of this differently so it makes more sense to use illustratively:\n",
    "\n",
    "$P(Disease | Testing Positive) =  \\frac{ P(Disease) P(Testing Positive | Disease)}{P(Disease) P(Testing Positive | Disease) + P(No Disease) P(Testing Positive | No Disease)}$\n",
    "\n",
    "$P(Test Positive | Disease) = 1 - False Negative $, \n",
    "\n",
    "where our FN = $4\\%$\n",
    "\n",
    "$P(No Disease) = 1 - P(Disease) = 1- .01$, \n",
    "\n",
    "since you have a $1\\%$ chance of having disease\n",
    "\n",
    "$P(Testing Positive | No Disease) = False Positve = 3\\% = 0.03$\n",
    "\n",
    "\n",
    "$P(Disease | Testing Positive) = \\frac{(0.01)(1-.04)}{(0.01)(1-0.04)+(1-0.01)(0.03)} = \\frac{0.0096}{0.0396} = .24242 = 24\\%$\n",
    "\n",
    "<font color=red>ANSWER</font>: $24\\%$\n",
    "\n",
    "`---------------------------`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ex. 2 )** In general, how does the introduction of a regularization term affect a cost function?\n",
    "\n",
    "`Answers`:\n",
    "\n",
    "+ It adds a term to account for Gaussian Noise\n",
    "+ Ensures the cost function is convex\n",
    "+ Doesn't affect the cost function\n",
    "+ Penalizes large parameter values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Work It Out`**:\n",
    "\n",
    "<font color=red> ANSWER</font>\n",
    "\n",
    "+ First, we need to go to the basics, we always want to minimize overfitting and generalize our model. We are not in the business of tailoring a model for only one use case such as that particular data. You want to evaluate the ability to model new data coming in, something that has never been seen.\n",
    "+ You are decreasing the amount of variance while minimally increasing bias.\n",
    "\n",
    "\n",
    "`Regularization` : is a technique used for adding a penalty term, allowing you to tune your model. Think of adding more penalty the more complex the model becomes.\n",
    "\n",
    "`Gaussian Noise`: You can add noise to a Neural Network to act like a regularization term if you have a small training set in order to avoid overfitting.\n",
    "\n",
    "`Ensure Convex Cost Function`: No, it only works in some situations where you have convexity (like certain regression models).\n",
    "\n",
    "\n",
    "https://machinelearningmastery.com/how-to-improve-deep-learning-model-robustness-by-adding-noise/\n",
    "\n",
    "https://towardsdatascience.com/how-to-use-noise-to-your-advantage-5301071d9dc3\n",
    "\n",
    "\n",
    "`-------------------------------------`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ex. 3 )** What is the difference between k-nearest neighbor and k-means?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Work It Out`\n",
    "\n",
    "<font color=red>ANSWER</font>\n",
    "\n",
    "`k-nearest neighbors`: classification problem, as well as regression [*But, more often used in classification*]\n",
    "+ Think of similarity by some distance\n",
    "    + What is the (k) that we need to select anyway? Well, this is a supervised algorithm which means that we are placing input and seeing how it reacts. From there we change (k) based on the error we receive back.\n",
    "        + Although, we may descrease (k), you do need to realize that you will have less stable predictions going toward (1). The reverse can cause similar problems with error as well. \n",
    "\n",
    "+ No underlying assumptions\n",
    "\n",
    "`k-means`: clustering algorithm\n",
    "\n",
    "+ partition observations into clusters, the (k) infers the number of clusters you will use. This can be found be using something such as a scree plot to give an idea of how many to use. \n",
    "    + minimizes the within cluster variance between\n",
    "\n",
    "`---------------------------------`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ex. 4 )** What is the difference between type-I and type-II error?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Work It Out`**:\n",
    "\n",
    "<font color=red> ANSWER</font>:\n",
    "\n",
    "`Type-I`: when you reject a (True) null hypothesis\n",
    "\n",
    "`Type-II`: keep a false null hypothesis\n",
    "\n",
    "`-----------------------------`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ex 5. )** Explain what Precision and recall are. Would they be related to an `ROC` curve?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Work It Out`**\n",
    "\n",
    "`------------------`\n",
    "\n",
    "<font color=red>ANSWERS</font>\n",
    "\n",
    "`Precision`: percentage of true positives, \n",
    "\n",
    "`Recall`: percent of correct (positive) predictions\n",
    "\n",
    "`ROC Curve`: relationship between recall and specificity (*percent true negatives*).\n",
    "\n",
    "*Putting together*: all 3 deal with how well a classification is for a model\n",
    "\n",
    "https://www.kdnuggets.com/faq/precision-recall.html\n",
    "\n",
    "`---------------------------`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ex 6. )** L1 vs L2 regularization? (*explain*)\n",
    "\n",
    "<font color=red>ANSWER</font>\n",
    "\n",
    "`L1 norm`: Lasso, penalizes the high coefficients and used for variable selection\n",
    "\n",
    "+ Shrinks less important feature (*coefficients to zero*)\n",
    "\n",
    "`L2 norm`: Ridge, bias variance tradeoff.\n",
    "\n",
    "\n",
    "*the penalty term is main difference*:\n",
    "\n",
    "`Ridge`: $\\lambda \\sum^p_{j=1} \\beta^2_j$ \n",
    "\n",
    "\n",
    "`Lasso`: $\\lambda \\sum^p_{j=1} |\\beta_j|$\n",
    "\n",
    "https://towardsdatascience.com/l1-and-l2-regularization-methods-ce25e7fc831c\n",
    "\n",
    "\n",
    "`--------------------------------`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ex 7. )** Are there limitations or disadvantages to using Linear Models?\n",
    "\n",
    "`Work It Out`\n",
    "\n",
    "<font color=red>ANSWER</font>:\n",
    "\n",
    "+ `Outliers`: are an issue and can drastically change the model\n",
    "\n",
    "\n",
    "+ `Overfitting`: this can happen if you start modeling the (*random*) noise instead of the actual relationship of the data.\n",
    "\n",
    "\n",
    "+ If your data is NOT linear then you will have a üí© model. But, there are cases when you have the ability to do a transformation to your data (log, square root) for example.\n",
    "\n",
    "\n",
    "+ You have an assumption that your attributes are independent, uh oh what if there's auto-correlation üßê\n",
    "\n",
    "https://www.quora.com/What-are-the-limitations-of-linear-regression-modeling-in-data-analysis\n",
    "\n",
    "https://www.geeksforgeeks.org/ml-advantages-and-disadvantages-of-linear-regression/\n",
    "\n",
    "`-----------------------------------`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ex. 8 )** You have a dataset that your boss gave you; but you do some investigation and notice there are a few highly correlation variables. You are asked to perform Principal Component Analysis (*PCA*). How should you proceed?\n",
    "\n",
    "+ Use PCA, and don't touch the variables\n",
    "\n",
    "+ Deal with correlated variables and move to doing PCA.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Work It Out`\n",
    "\n",
    "<font color=red>ANSWER</font>\n",
    "\n",
    "This is an interesting problem and elusive, because PCA would seem to take care of the correlation: but, that would actually create dubious results. This is beacause of the explained variance becoming exaggerated by the number of correlated variables. Discarding them would be appropriate because of this. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`----------------------------------------`\n",
    "\n",
    "**Ex 9. )** What considerations should you take when dealing with `Multi-collinearity`?\n",
    "\n",
    "`Work It Out`\n",
    "\n",
    "<font color=red>ANSWER</font>\n",
    "\n",
    "This occurs when independent variables in your regression model have some relationship. You incur a problem because, estimating the relationship of the independent variable to the dependent variable. \n",
    "\n",
    "`Consider`:\n",
    "+ Losing Information, if you discard arbitrarily\n",
    "+ Interpreting coefficients is difficult\n",
    "+ p-values will be off and precision \n",
    "\n",
    "\n",
    "There are a few things you can do to try and work through this:\n",
    "\n",
    "+ If you have an idea of what variables are causing your headache, look into the strength of the correlation using Variance Inflation Factors (VIF). \n",
    "    + This will output a a value which will tell you if you can rely on the p-values or not. \n",
    "    For example: if the values is 1, then you have NO correlation\n",
    "    1-5 moderate correlation \n",
    "    and >5 correlated. \n",
    "    \n",
    "+ Penalizing terms: such as Lasso and Ridge regression can be useful as well\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "https://statisticsbyjim.com/regression/multicollinearity-in-regression-analysis/\n",
    "\n",
    "`---------------------------------------`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ex 10. )** Give me a few ways that you would use to select important/useful variables?\n",
    "\n",
    "`Work It Out`\n",
    "\n",
    "<font color=red>ANSWER</font>\n",
    "\n",
    "+ LASSO\n",
    "+ Feature selection using: Forward or Back selection\n",
    "+ Try to remove correlated variables\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "`-------------------------`\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=red>Like</font> , Share &\n",
    "\n",
    "# <font color=red> SUB</font>scribe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources & Help:\n",
    "  \n",
    "# ‚óîÃØ‚óî\n",
    "\n",
    "\n",
    "`SVD`:\n",
    "\n",
    "https://blog.statsbot.co/singular-value-decomposition-tutorial-52c695315254\n",
    "\n",
    "http://mitran-lab.amath.unc.edu/courses/MATH547/lessons/Lesson24.pdf\n",
    "\n",
    "https://medium.com/@jonathan_hui/machine-learning-singular-value-decomposition-svd-principal-component-analysis-pca-1d45e885e491\n",
    "\n",
    "https://courses.cs.washington.edu/courses/cse521/16sp/521-lecture-9.pdf\n",
    "\n",
    "http://users.wpi.edu/~martin/MEETINGS/LINESTALKS/Romberg.pdf\n",
    "\n",
    "`Regularization`: \n",
    "\n",
    "https://towardsdatascience.com/regularization-an-important-concept-in-machine-learning-5891628907ea\n",
    "\n",
    "https://towardsdatascience.com/regularization-in-machine-learning-76441ddcf99a\n",
    "\n",
    "https://cmci.colorado.edu/classes/INFO-4604/files/slides-6_regularization.pdf\n",
    "\n",
    "https://www.cs.ubc.ca/~schmidtm/Courses/340-F17/T6.pdf\n",
    "\n",
    "https://medium.com/towards-artificial-intelligence/how-regularization-can-help-in-overfitting-the-data-ad9ff80f9ccc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the following is an example of singular value decomposition (*SVD*)?\n",
    "\n",
    "+ Converting a matrix into Jordan form\n",
    "+ Inverting a singular matrix\n",
    "+ Finding a low-rank approximation of a matrix\n",
    "+ Solving an overdetermined system of linear equations\n",
    "\n",
    "\n",
    "**`Work It Out`**:\n",
    "\n",
    "<font color=red>ANSWER</font>\n",
    "\n",
    "What is going on at a basic level:\n",
    "\n",
    "$A = U \\Sigma V^T$\n",
    "\n",
    "$\\Sigma =$ diagonal matrix and contains the values of A\n",
    "\n",
    "$U_{mxm}$ and $V_{nxn}$ are orthogonal matrices\n",
    "\n",
    "+ We do a rotation of $V^T$\n",
    "    + Then Scale\n",
    "        + Finally, rotate U\n",
    "\n",
    "\n",
    "*The columns of U and V are left and right singular vectors*\n",
    "\n",
    "+ \n",
    "\n",
    "+ Low-Rank approximation: is relevant because, you are\n",
    "\n",
    "+ Convert to Jordan form, is relevant: because it deals with diagonalization\n",
    "\n",
    "Good Read:\n",
    "https://medium.com/@jonathan_hui/machine-learning-singular-value-decomposition-svd-principal-component-analysis-pca-1d45e885e491\n",
    "\n",
    "http://pillowlab.princeton.edu/teaching/statneuro2018/slides/notes04_PCA.pdf\n",
    "\n",
    "http://www.iust.ac.ir/files/mech/madoliat_bcc09/pdf/SVD_19.pdf\n",
    "\n",
    "https://medium.com/@amelie_yeh/singular-value-decomposition-low-rank-approximation-5d867bf67404\n",
    "\n",
    "https://www.sciencedirect.com/topics/engineering/overdetermined-system\n",
    "\n",
    "http://mitran-lab.amath.unc.edu/courses/MATH547/lessons/Lesson24.pdf\n",
    "\n",
    "http://www.iust.ac.ir/files/mech/madoliat_bcc09/pdf/SVD_19.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
